{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring Your Own Model を SageMaker で hosting する\n",
    "* 先程学習したモデルを Notebook インスタンスで読み込み、改めて tensorflow で save し、自分で作成したモデルとする\n",
    "* 自作モデルを SageMaker で hosting & 推論する\n",
    "\n",
    "## 処理概要\n",
    "* 先程学習したモデルを Notebook インスタンスにダウンロード\n",
    "* TensorFlow で読み込み、推論し、改めて保存し直す\n",
    "* 保存しなおしたモデルを S3 にアップロードする\n",
    "* モデルを hosting する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook のセルの横方向の表示範囲を広げる\n",
    "from IPython.core.display import display, HTML \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, yaml, tarfile, boto3, os, json, boto3\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "print(f'Current tensorflow Version ={tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設定読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./setting.yaml', 'r') as yml:\n",
    "    config = yaml.load(yml)\n",
    "best_model_uri = config['best_model_uri']\n",
    "name = config['name']\n",
    "timestamp = config['timestamp']\n",
    "print(best_model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを Notebook インスタンスにダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.s3.S3Downloader.download(\n",
    "    s3_uri=best_model_uri,\n",
    "    local_path='./model/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tar.gz の解凍\n",
    "with tarfile.open('./model/model.tar.gz') as tar:\n",
    "    tar.extractall('./model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの読み込み\n",
    "* SageMaker Training で学習したものは当然ながら TensorFlow で学習したものと同一\n",
    "* load してそのまま使えるかを確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./model/000000001/')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.load('./test_x.npy')\n",
    "plt.imshow(test_x[0,:,:,0],'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.predict(test_x[0:1,:,:,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ダウンロードしたモデルを削除し、改めて保存しなおす\n",
    "* tensorflow の save を利用して保存した後、tar.gz に圧縮する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './000000002'\n",
    "tar_name = os.path.join(model_dir, 'model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(model_dir)\n",
    "with tarfile.open(tar_name, mode='w:gz') as tar:\n",
    "    tar.add(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tar.gz に圧縮したモデルを S3 にアップロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.session.Session()\n",
    "bucket = sess.default_bucket()\n",
    "model_s3_path = f's3://{bucket}/{name}-model-{timestamp}'\n",
    "print(model_s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s3_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path = tar_name,\n",
    "    desired_s3_uri = model_s3_path\n",
    ")\n",
    "print(model_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 にアップロードしたモデルを SageMaker 管理のモデルとして登録する\n",
    "* TensorFlow で作成したモデルは [TensorFlowModel](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html?highlight=TensorFlowModel#sagemaker.tensorflow.model.TensorFlowModel) で読み込む\n",
    "* 推論に利用する TensorFlow のコンテナイメージを [sagemaker.image_uris.retrieve](https://sagemaker.readthedocs.io/en/stable/api/utility/image_uris.html?highlight=sagemaker.image_uris.retrieve#sagemaker.image_uris.retrieve) で事前に取得しておく(SageMaker にこのモデルは TensorFlow の 2.1 で作られたものであることを報せる必要がある）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_image_uri = sagemaker.image_uris.retrieve(\n",
    "    \"tensorflow\", \n",
    "    boto3.Session().region_name, \n",
    "    version='2.1',\n",
    "    instance_type = 'ml.m5.large',\n",
    "    image_scope = 'inference'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = TensorFlowModel(\n",
    "    model_data=model_s3_uri,\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    image_uri = container_image_uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hosting して推論の確認を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor = tf_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictor.predict(test_x[0:1,:,:,:])['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論のみを行う場合\n",
    "* 毎回モデルを読み込んで推論するわけではなく、ほとんどのケースでは モデルを hosting している endpoint で推論のみを行う\n",
    "* 今回は sagemaker sdk を利用して推論のみをする場合と、boto3 を用いて推論する場合の 2 種類を試す\n",
    "* 推論をするのに必要な情報は endpoint_name と推論するデータのみ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint_name を予め取得する (マネジメントコンソールでも確認可能)\n",
    "endpoint_name = predictor.endpoint_name\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sagemaker SDK を利用する場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor2 = sagemaker.predictor.Predictor(\n",
    "    endpoint_name,\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictor2.predict(test_x[0:1,:,:,:])['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boto3 を利用する場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps({\"instances\": test_x[0:1,:,:,:].tolist()}),\n",
    "    ContentType='application/json'\n",
    ")\n",
    "np.argmax(np.array(json.load(response['Body'])['predictions'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
